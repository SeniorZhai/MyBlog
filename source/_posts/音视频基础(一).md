title: 音视频基础(一)
date: 2020-11-01 21:15:44
categories: [ffmpeg]
tags: [ffmpeg]
---
## 视频帧
视频是由一系列图片构成，每一张画面即视频帧，视频由许许多多视频帧构成
<!--more-->

### 帧率
单位时间内帧的数量，单位是`帧/秒`(fps frames per second)，表示一秒内包含多少图片

## 色彩空间
- RGB
通过RGB光的三原色，混合所有颜色，广泛的引用在现在的电子设备中
- YUV
这是一种亮度与色度分离的色彩格式
早起的电视都是黑白的，即只有亮度Y，有了彩色电视后，加入了UV两个色度，形成了YUV也叫YCbCr
Y: 亮度，即灰度值，表示亮度以外还包含较多的绿色通道量
U: 蓝色通道与亮度的差值
V: 红色通道与亮度的差值

> 人眼对亮度敏感，对色度不敏感，因此减少部分UV的数据量，人眼也无法感知，通过压缩UV的分辨率，在不怎么影响观感的前提下，可以减小视频的体积

### RGB与YUV的换算
```
Y = 0.299R + 0.587G + 0.1148
U = -0.147R - 0.289G + 0.436B
V = 0.615R - 0.515G - 0.100B
----------------------------
R = Y + 1.114V
G = Y - 0.39U - 0.58V
B = Y + 2.03U
```

# 音频
音频的数据承载方式常见`脉冲编码调制`，`PCM`
声音是一种波，有自己的振幅和频率，保存声音就是保存声音在各个时间点上的振幅，数字信号并不能连续保存所有时间点的振幅。
根据奈奎斯特采样定理：为了不失真地恢复模拟信号，采样率应该不小于模拟信号频谱中最高频率的2倍
PCM采集步骤：
> 模拟信号->采样->量化->编码->数字信号
![](/img/20110101.webp)

## 采样率和采样位数
采样率即采样的频率
采样率要大于原声频率的2倍，人耳听到的最高的频率为20kHz，为了满足人耳听觉要求采样率至少为40kHz，通常为44.1kHz，更高的通常为48kHz。
波形振幅在模拟信号上也是连续的样本值，而在数字信号中，信号不连续，所以模拟信号量化后，只能取一个近似值的整数值，为了记录这些振幅值，采样器会采用一个固定的位数来记录这些振幅值，通常有8位、16位、32位。
|位数|最小值|最大值|
|:--|:--|:--|
|8|0|255|
|16|-32768|32767|
|32|-2147483648|214748367|

![](/img/20110102.jpg)

### 声道数
指支持不同发声的音响的个数

### 码率
码率值一个数据流中每秒能通过的信息量，单位bps（bit per second)
码率 = 采样率 * 采样位数 * 声道数

## 视频编码
视频编码格式有很多，比如H26x和MPEG系列编码
其中 H26X(1/2/3/4/5) 系列由ITU(International Telecommunication Union)国际电视视讯联盟主导
MPEG(1/2/3/4) 系列由MPEG(Moving Picture Experts Group,ISO旗下组织)主导

### H264
目前最流行的视频编码标准
`H264`由ITU和MPEG共同定制，属于MPEG-4第十部分内容
- 视频由一帧帧的画面组成，但是视频中大多数画面内容相近，所以视频的数据不是所有的画面原始数据
H264会根据一段时间内，画面的变化情况，选取一帧画面作为完整编码，下一阵只记录与上一帧完整数据的差别
在H264中，三种类型的帧数据分别为
`I帧`: 帧内编码帧，就是一个完整帧
`P帧`: 前向预测编码帧，是一个非完整帧，通过参考前面的I帧或P帧生成
`B帧`: 双向预测内编码帧，参考前后图像帧编码生成，B帧依赖其前最近的一个I帧或P帧以及其后最近的一个P帧
- 图像组GOP 和 关键帧IDR
Group of picture 指一组变化不大的视频组
IDR都是I帧，可以防止一帧解码出错，导致后面的所有帧解码出错。当加码器在解码到IDR时，会将之前的参考帧清空，重新开始一个新的序列。这样即使前一帧出现重大的错误，也不会蔓延都后续的数据中。
- DTS 和 PTS
DTS Decoding Time Stamp 标示读入内存中数据流在什么时候开始送入解码器中进行解码，也就是编码顺序的时间戳
PTS Presentation Time Stamp 标示编码后的视频什么时候被显示出来
- 帧的色彩空间
H264采用的是YUV
YUV存储方式分为两大类：planar和packed
planar 先存储Y紧接着存储U最后是V
packed 像素点的Y、U、V连续交叉存储
![](/img/20110103.webp)
![](/img/20110104.webp)
因为人眼对色度不敏感，所以可以通过省略一定的色度信息，即亮度公用一些色度信息进而节省存储空间，planar又区分了以下几种格式: YUV444、YUV422、YUV420
YUV 4:4:4 每个Y对应一组UV分量
![](/img/20110105.webp)
YUV 4:2:2 每两个Y公用一组UV分量
![](/img/20110106.webp)
YUV 4:2:0 每四个Y公用一组UV分量
![](/img/20110107.webp)
其中最常用的就是YUV420
-YUV420属于planar存储方式
YUV420P 三面存储 数据组成为YYYYYYYYUUVV（如I420）或YYYYYYYYVVUU（如YV12）
YUV420SP：两平面存储 分为两种类型YYYYYYYYUVUV（如NV12）或YYYYYYYYVUVU（如NV21）

## 音频编码
原始的PCM音频数据也是非常大的数据量，因此也需要对其进行压缩编码
音频的编码格式也有许多，比如 WAV MP3 WMA APE FLAC等等，后两种属于无损压缩格式
AAC是一种有损压缩技术，一种高压缩比的音频压缩算法，MP4视频中的音频数据，大多数时候都是采用AAC压缩格式
主要分为ADIF、ADTS
ADIF Audio Data Interchange Format 音频数据交换格式，这种格式的特征是可以确定的这个音频数据的开始，不需要进行音频数据中间开始解码，即它的编码必须在明确的开始处进行。

ADTS Audio Data Transport Strem 音频数据数据传输流，它是一个同步的比特流，解码可以在任意位置开始。

ADIF 数据
|header|raw_data|
|:--|:--|
ADTS 一帧 数据格式
|…|sync_word|header|error_check|raw_data|…|
|:--|:--|:--|:--|:--|:--|

## 音频容器
常见的音视频格式map4、rmvb、avi、mkv、mov就是音视频编码数据的容器，用来把特定的标准编码的视频流和音频流混在一起

## 硬解码和软解码
硬解码指CPU、GPU等加码器硬件进行解码
软解码利用CPU计算能力进行解码，由于CPU的性能可能会比较慢和造成CPU发热，但是因为统一的算法，兼容性很好
